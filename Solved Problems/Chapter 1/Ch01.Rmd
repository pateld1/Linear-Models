---
title: 'ALSM: Chapter 1'
subtitle: 'Linear Regression with One Predictor Variable'
author: "Darshan Patel"
date: "12/19/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(latex2exp)
library(ALSM)
```


### Problem 1: 
Refer to the sales volume example on page 3. Suppose that the number of units sold is measured accurately, bur clerical errors are frequently made in determining the dollar sales. Would the relation between the number of units sold and dollar sales still be a functional one? Discuss.

Answer: The relationship between the number of units sold and dollar sales would not be a functional one because there is no direct relationship due to the errors made.


### Problem 2: 
The members of a health spa pay annual membership dues of \$300 plus a charge of \$2 for each visit to the spa. Let $Y$ denote the dollar cost for the year for a member and $X$ the number of visits by the member during the year. Express the relation between $X$ and $Y$ mathematically. Is it a functional relation or a statistical relation?

Answer: The relationship between $X$ and $Y$ can be expressed as $$ Y = 2X + 300 $$ This is a functional relationship.

### Problem 3: 
Experience with a certain type of plastic indicates that a relation exists between the hardness (measured in Brinell units) of items molded from the plastic ($Y$) and the elapsed time since termination of the molding process ($X$). It is proposed to study this relation by means of regression analysis. A participant in the discussion objects, pointing out that the hardening of the plastic "is the result of a natural chemical process that doesn't leave anything to chance, so the relation must be mathematical and regression analysis is not appropriate." Evaluate this objection.

Answer: The relation would still be one that can be studied through a regression point of view. Whether the relationship is functional or statistical will be tested by measuring the hardness of plastic versus elapsed time since the termination of the molding process.

### Problem 4: 
In Table 1.1, the lot size $X$ is the same in production runs $1$ and $24$ but the work hours $Y$ differ. What feature of regression model (1.1) is illustrated by this?

Answer: The work hours $Y$ differ because of the random error term $\varepsilon$. 

### Problem 5: 
When asked to state the simple linear regression model, a student wrote it as follows: $E[Y_i] = \beta_0 + \beta_1X_i + \varepsilon$. Do you agree?

Answer: No. The expected value of the error term is zero and thus falls out of $E[Y_i]$ which is the expected value of a single observation.

### Problem 6: 
Consider the normal error regression model (1.24). Suppose that the parameter values are $\beta_0 = 200$, $\beta_1 = 5.0$ and $\sigma = 4$. 

(a) Plot the normal error regression model in the fashion of Figure 1.6. Show the distributions of $Y$ for $X=10,~20$, and $40$. 

Answer:
```{r}
seq_maker = function(y){return(seq(y - (4*3), y + (4*3), length.out = 200))}

data.frame(x = c(10, 20, 40)) %>%
  mutate(y = 200 + (5*x)) %>%
  ggplot(aes(x,y)) + geom_point(size = 0.75) + 
  geom_abline(intercept = 200, slope = 5, color = "cornflowerblue", 
                 linetype="dotted", size = 1) + 
  geom_path(data = data.frame(y = seq_maker(250),
                              x = 10 + 25*dnorm(seq_maker(250), 
                                                mean = 250, sd = 4)), aes(x,y)) +
  geom_path(data = data.frame(y = seq_maker(300),
                              x = 20 + 25*dnorm(seq_maker(300), 
                                                mean = 300, sd = 4)), aes(x,y)) + 
  geom_path(data = data.frame(y = seq_maker(400),
                              x = 40 + 25*dnorm(seq_maker(400), 
                                                mean = 400, sd = 4)), aes(x,y)) + 
  labs(title = "Normal Error Regression Model",
       subtitle = TeX("with Probability Distributions for $X = 10, 20, 40$")) + 
  theme_minimal()
```

(b) Explain the meaning of the parameters $\beta_0$ and $\beta_1$. Assume that the scope of the model includes $X=0$.

Answer: The parameter $\beta_0$ refers to the $y$-intercept of the regression function (where $X=0$). The parameter $\beta_1$ refers to the slope of the regressopn function. 

### Problem 7: 
In a simulation exercise, regression model (1.1) applies with $\beta_0 = 100$, $\beta_1 = 20$ and $\sigma^2 = 25$. An observation on $Y$ will be made for $X=5$.

(a) Can you state the exact probability that $Y$ will fall between $195$ and $205$? Explain.

Answer: The exact probability that $Y$ will fall between $195$ and $205$ is not determinable because the probability distribution of $Y$ needs to be defined first.

(b) If the normal error regression model (1.24) is applicable, can you now state the exact probability that $Y$ will fall between $195$ and $205$? If so, state it.

Answer: Now that the normal error regression model is applicable, it can be assumed that the probability distribution of $Y$ is normal with mean $\beta_0 + \beta_1X_i = 100 + 20*5 = 200$ and variance $25$. Hence the probability that $Y$ will fall between $195$ and $205$ is
```{r}
pnorm(205, mean = 200, sd = 5, lower.tail = TRUE) - 
  pnorm(195, mean = 200, sd = 5, lower.tail = TRUE)
```

In essense this is one standard deviation above and below the mean.

### Problem 8: 
In Figure 1.6, suppose another $Y$ observation is obtained at $X=45$. Would $E[Y]$ for this new observation still be $104$? Would the $Y$ value for this new case again be $108$?

Answer: In figure 1.6, the following is shown.

![](fig1.6.png){#id .class width=50% height=50%}

If another $Y$ observation is obtained at $X=45$, then $E[Y]$ would still be $104$ since the model has not been tweaked. The $Y$ value for this new case would be $108$ since this is the actual number of hours required.

### Problem 9: 
A student in accounting enthusiastically declared: "Regression is a very powerful tool. We can isolate fixed and variable costs by fitting a linear regression model, even when we have no data for small lots." Discuss.

Answer: This statement is correct. The fixed cost can be defined by the $y$-intercept of a regression model while the variable cost can be defined by the slope of the model.


### Problem 10: 
An analyst in a large corporation studied the relation between current annual salary ($Y$) and age ($X$) for the $46$ computer programmers presently employed in the company. The analyst concluded that the relation is curvilinear, reaching a maximum at $47$ years. Does this imply that the salary for a programmer increases until age $47$ and then decreases? Explain.

Answer: This conclusion says that the maximum is reached at $47$ years but not if the annual salary decreases or stays constant afterwards. Thus salary for a programmer beyond $47$ cannot be extrapolated.


### Problem 11:
The regression function relating production output by an employee after taking a training program ($Y$) to the production output before the training program ($X$) is $E[Y] = 20 + .95X$, where $X$ ranges from $40$ to $100$. An observer concludes that the training program does not raise production output on the average because $\beta_1$ is not greater than $1.0$. Comment.

Answer: 
```{r}
data.frame(x = 40:100, y = 20 + 0.95*40:100) %>%
  ggplot(aes(x,y)) + geom_path(color = "blue4") + 
  geom_abline(slope = 1, intercept = 0, color = "darkgreen") + 
  annotate("text", label = "no program", x = 80, y = 65) + 
  annotate("text", label = "after program", x = 60, y = 90) + 
  labs(x = "production output before the training program",
       y = "production output after the training program", 
       title = "Effect of Training Output") + 
  lims(x = c(40, 100)) + 
  coord_cartesian() + 
  theme_classic()
```

This conclusion is not valid because, in the range of $X$, the production output after the training program, $Y$, is greater than $X$. 

### Problem 12: 
In a study of the relationship for senior citizens between physical activity and frequency of colds, participants were asked to monitor their weekly time spent in exercise over a five-year period and the frequency of colds. The study demonstrated that a negative statistical relation exists between time spent in exercise and frequency of colds. The investigator concluded that increasing the time spent in exercise is an effective strategy for reducing the frequency of colds for senior citizens.

(a) Were the data obtained in the study observational or experimental data?

Answer: The data obtained in the study is observational data because the explanatory variable (time spent in exercise) was not controlled. 

(b) Comment on the validity of the conclusions reached by the investigator.

Answer: Just because there is a correlation between the time spent exercising and frequency of colds does not indicate there is a cause and effect relationship. The conclusion reached by the investigator is invalid. 

(c) Identify two or three other explanatory variables that might affect both the time spent in exercise and the frequency of colds for senior citizens simultaneously.

Answer: Other variables that might affect both the time spent in exercise and the frequency of colds are: age and sleep pattern. 

(d) How might the study be changed so that a valid conclusion about causal relationship between amount of exercise and frequency of colds can be reached?

Answer: The study can be changed by implementing a completely randomized design where random groups of elderly people are sentenced to specific amount of exercise and their frequency of colds is recorded. 


### Problem 13: 
Computer programmers employed by a software developer were asked to participate in a month- long training seminar. During the seminar, each employee was asked to record the number of hours spent in class preparation each week. After completing the seminar, the productivity level of each participant was measured. A positive linear statistical relationship between participants' productivity levels and time spent in class preparation was found. The seminar leader concluded that increases in employee productivity are caused by increased class preparation time.

(a) Were the data used by the seminar leader observational or experimental data?

Answer: The data used by the similar leader is observational data because the number of hours spent in class preparation is determined by the employees.

(b) Comment on the validity of the conclusion reached by the seminar leader.

Answer: The conclusion reached by the seminar leader cannot be reacted simply due to a correlation. 

(c) Identify two or three alternative variables that might cause both the employee productivity scores and the employee class participation times to increase (decrease) simultaneously.

Answer: Alternative variables that might have an effect are: ability to stay attentive, age, and level of enthusiasm. 

(d) How might the study be changed so that a valid conclusion about causal relationship between class preparation time and employee productivity can be reached?

Answer: Use a completely randomized design to randomly assign employees with the number of hours to spend in participating and then measuring their productivity level. 

### Problem 14: 
Refer to Problem 1.3. Four different elapsed times since termination of the molding process (treatments) are to be studied to see how they affect the hardness of a plastic. Sixteen batches (experimental units) are available for the study. Each treatment is to be assigned to four experimental units selected at random. Use a table of random digits or a random number generator to make an appropriate randomization of assignments.

Answer: Let the 4 different elapsed times be represented by A, B, C, D. Then an appropriate randomization of 16 assignments is
```{r}
sample(rep(c('A', 'B', 'C', 'D'), 4))
```

### Problem 15:
The effects of five dose levels are to be studied in a completely randomized design, and 20 experimental units are available. Each dose level is to be assigned to four experimental units selected at random. Use a table of random digits or a random number generator to make an appropriate randomization of assignments.

Answer: Let the 5 different dose levels be represented by D1, D2, D3, D4, D5. Then an appropriate randomization of 20 assignments is
```{r}
sample(rep(c('D1', 'D2', 'D3', 'D4', 'D5'), 4))
```

### Problem 16: 
Evaluate the following statement:"For the least squares method to be fully valid, it is required that the distribution of $Y$ be normal."

Answer: The distribution of $Y$ does not need to be normal in order to run the least squares method. 


### Problem 17:
A person states that $b_0$ and $b_1$ in the fitted regression function (1.13) can be estimated by the method of least squares. Comment.

Answer: The fitted regression function is $$ \hat{Y}_i = b_0 + b_1X_i $$ where $\hat{Y}_i$ is the fitted value for the $i$th case. It is not the observed value $Y_i$ and thus $b_0$ and $b_1$ cannot be estimated by the method of least squares since those are derived from original $X$ and $Y$ obsrerved values.

### Problem 18: 
According to (1.17), $\sum e_i = 0$ when regression model (1.1) is fitted to a set of $n$ cases by the method of least squares. Is it also true that $\sum \varepsilon_i = 0$? Comment.

Answer: It is not true that $\sum \varepsilon_i = 0$ because $\varepsilon_i$ is a nonzero constant for all $i=1,\dots,n$ and the sum will not be zero. 

### Problem 19: 
*Grade point average.* The director of admissions of a small college selected $120$ students at random from the new freshman class in a study to determine whether a student's grade point average (GPA) at the end of the freshman year ($Y$) can be predicted from the ACT test score ($X$). The results of the study follow. Assume that first-order regression model (1.1) is appropriate.

(a) Obtain the least squares estimators of $\beta_0$ and $\beta_1$ and state the regression function.

Answer:
```{r}
gpa = read.csv('CH01PR19.txt', sep = '', header = FALSE, 
               col.names = c('y', 'x'), 
               colClasses = c('numeric', 'numeric'))

lm.fit_manual = function(X, Y){
  b1 = sum((X - mean(X))*(Y - mean(Y))) / (sum((X - mean(X))^2))
  b0 = mean(Y) - b1*mean(X)
  return(c(round(b0, 3), round(b1, 3)))
}

ls_est19 = lm.fit_manual(gpa$x, gpa$y)
```

Using the least squares method, the estimate for $\beta_0$ is `r paste('b0 = ', ls_est19[1])` and the estimate for $\beta_1$ is `r paste('b1 = ', ls_est19[2])`. The regression function is $$ Y = 2.114 + 0.039X $$ 

(b) Plot the estimated regression function and the data. Does the estimated regression function appear to fit the data well?
```{r}
ggplot(gpa, aes(x,y)) + geom_point(size = 0.8) + 
  geom_abline(intercept = ls_est19[1], slope = ls_est19[2], color = "cadetblue") + 
  labs(title = "GPA Prediction", subtitle = "from ACT test score", 
       x = "ACT Test Score", y = "GPA") + 
  theme_classic()
```

The estimated regression function appears to fit the data decently. Using a polynomial fit may be better. 

(c) Obtain a point estimate of the mean freshman GPA for studenets with ACT test score $X=30$.

Answer: 
```{r}
paste("The mean freshman GPA for students with an ACT test score of 30 is", 
      ls_est19[1] + (ls_est19[2]*30))
```

(d) What is the point estimate of the change in the mean response when the entrance test score increases by one point?

Answer: When the entrance test score increases by one point, the change in the mean response is `r ls_est19[2]`.


### Problem 20:
*Copier maintenance.* The Tri-City Office Equipment Corporation sells an imported copier on a franchise basis and performs preventive maintenance and repair service on this copier. The data below have been collected from $45$ recent calls on users to perform routine preventive maintenance service; for each call, $X$ is the number of copiers serviced and $Y$ is the total number of minutes spent by the service person. Assume that first-order regression model (1.1) is appropriate.

(a) Obtain the estimated regression function.

Answer: 
```{r}
copier = read.csv('CH01PR20.txt', sep = '', header = FALSE, 
                  col.names = c('y', 'x'), 
                  colClasses = c('numeric', 'numeric'))
ls_est20 = lm.fit_manual(copier$x, copier$y)
```

Using the least squares method, the estimate for $\beta_0$ is `r paste('b0 = ', ls_est20[1])` and the estimate for $\beta_1$ is `r paste('b1 = ', ls_est20[2])`. The regression function is $$ Y = -0.580 + 15.035X $$ 

(b) Plot the estimated regression function and the data. How well does the estimated regression function fit the data? 

Answer:
```{r}
ggplot(copier, aes(x,y)) + geom_point(size = 0.8) + 
  geom_abline(intercept = ls_est20[1], slope = ls_est20[2], color = "cadetblue") + 
  labs(title = "Copier Maintenance", 
       subtitle = "by the Tri-City Office Equipment Corporation", 
       x = "number of copiers serviced", y = "number of minutes") + 
  theme_classic()
```

The estimated regression function fits the data well. 

(c) Interpret $b_0$ in your estimated regression function. Does $b_0$ provide any relevant information here? Explain.

Answer: $b_0$ gives the total number of minutes spent by the service person when $x=0$. In this scenario, it does not make sense because when $x=0$, there are no copiers being serviced. 

(d) Obtain a point estimate of the mean service time when $X=5$ copiers are serviced.

Answer: When $X=5$ copiers are serviced, the mean service time is `r ls_est20[1] + 5*ls_est20[2]` minutes.

### Problem 21: 
*Airfreight breakage.* A substance used in biological and medical research is shipped by airfreight to users in cartons of $1,000$ ampules. The data, involving $10$ shipments, were collected on the number of times the carton was transferred from one aircraft to another over the shipment route ($X$) and the number of ampules found to be broken upon arrival ($Y$). Assume that first-order regression model (1.1) is appropriate.

(a) Obtain the estimated regression function. Plot the estimated regression function and the data. Does a linear regression function appear to give a good fit here?

Answer: 
```{r}
airfreight = read.csv('CH01PR21.txt', sep = '', header = FALSE, 
                  col.names = c('y', 'x'), 
                  colClasses = c('numeric', 'numeric'))
ls_est21 = lm.fit_manual(airfreight$x, airfreight$y)
```

The estimated regression function is $$ Y = 10.2 + 4.0X $$ 

```{r}
ggplot(airfreight, aes(x,y)) + geom_point(size = 0.8) + 
  geom_abline(intercept = ls_est21[1], slope = ls_est21[2], color = "cadetblue") + 
  labs(title = "Broken Ampules", 
       subtitle = "due to shipment transfers by airfreight", 
       x = "number of transfers", y = "number of broken ampules") + 
  theme_classic()
```

The linear regression function appears to give a good fit here. 

(b) Obtain a point estimate of the expected number of broken ampules when $X=1$ transfer is made. 

Answer: When one transfer is made, the expected number of broken ampules is `r ls_est21[1] + 1*ls_est21[2]`. 

(c) Estimate the increase in the expected number of ampules broken when there are $2$ transfers as compared to $1$ transfer.

Answer: When there are $2$ transfers, there are twice as many expected broken ampules, or `r 2* ls_est21[2]`, than when there is only one transfer, or `r ls_est21[2]`.

(d) Verify that your fitted regression line goes through the point ($\overline{X}, \overline{Y}$). 

Answer: To verify the fitted regression line goes through this point, verify that $$ \overline{Y} - (b_0 + b_1*\overline{X}) = 0 $$ 
```{r}
mean(airfreight$y) - (ls_est21[1] + ls_est21[2]*mean(airfreight$x))
```

### Problem 22: 
*Plastic hardness.* Refer to Problems 1.3 and 1.14. Sixteen batches of the plastic were made, and from each batch one test item was molded. Each test item was randomly assigned to one of the four predetermined time levels, and the hardness was measured after the assigned elapsed time. $X$ is the elapsed time in hours and $Y$ is hardness in Brinell units. Assume that first-order regression model (1.1) is appropriate.

(a) Obtain the estimated regression function. Plot the estimated regression function and the data. Does a linear regression function appear to give a good fit here?

Answer:
```{r}
plastic = read.csv('CH01PR22.txt', sep = '', header = FALSE, 
                  col.names = c('y', 'x'), 
                  colClasses = c('numeric', 'numeric'))
ls_est22 = lm.fit_manual(plastic$x, plastic$y)
```

The estimated regression function is $$ Y = 168.6 + 2.034X $$ 

```{r}
ggplot(plastic, aes(x,y)) + geom_point(size = 0.8) + 
  geom_abline(intercept = ls_est22[1], slope = ls_est22[2], color = "cadetblue") + 
  labs(title = "Hardness of Plastic", 
       subtitle = "after elapsed molding time", 
       x = "elapsed time, in hrs", y = "hardness, in Brinell units") + 
  theme_classic()
```

The linear regression function appears to be a good fit here.

(b) Obtain a point estimate of the mean hardness when $X=40$ hours.

Answer: When the elapsed time is $X=40$ hours, then the mean hardness is `r ls_est22[1] + 40*ls_est22[2]` Brinell units. 

(c) Obtain a point estimate of the change in mean hardness when $X$ increases by $1$ hour.

Answer: When $X$ increases by one hour, then the mean hardness increases by 2.034 on the Brinell units. 

### Problem 23:
Refer to *Grade point average* Problem 1.19. 

(a) Obtain the residuals $e_i$. Do they sum to zero in accord with (1.17)?

Answer:
```{r}
resid19 = gpa$y - (ls_est19[1] + ls_est19[2]*gpa$x)
sum(resid19)
```

The residuals do not sum to $0$. 

Note: When using the `lm` function in R which does not perform rounding, the residuals add up to nearly $0$.
```{r}
sum(lm(data = gpa, y~x)$residuals)
```

(b) Estimate $\sigma^2$ and $\sigma$. In what units is $\sigma$ expressed?

Answer: $\sigma^2$ and $\sigma$ are, respectively, 
```{r}
sd(resid19)^2
sd(resid19)
```

The units of $\sigma$ is the same as GPA scores. 

### Problem 24: 
Refer to *Copier maintenance* Problem 1.20.

(a) Obtain the residuals $e_i$ and the sum of the squared residuals $\sum e_i^2$. What is the relation between the sum of the squared residuals here and the quantity $Q$$ in (1.8)?

Answer:
```{r}
resid20 = copier$y - (ls_est20[1] + ls_est20[2]*copier$x)
sum(resid20^2)
```

The criterion given by Q: $$ Q = \sum_{i=1}^n (Y_i - \beta_0 - \beta_1X_i)^2 $$ is minimized using the method of least squares. When plugging in the values for $\beta_0$ and $\beta_1$, this value is minimized. The sum of the squared residuals is this criterion value since the algorithm seems to minimize the error created in estimation.

(b) Obtain point estimates of $\sigma^2$ and $\sigma$. In what units is $\sigma$ expressed?

Answer: $\sigma^2$ and $\sigma$ are, respectively,
```{r}
sd(resid20)^2
sd(resid20)
```

The units of $\sigma$ is minutes.

### Problem 25: 
Refer to *Airfreight breakage* Problem 1.21.

(a) Obtain the residual for the first case. What is its relation to $\varepsilon_1$?

Answer:
```{r}
resid21 = airfreight$y - (ls_est21[1] + ls_est21[2]*airfreight$x)
resid21[1]
```

$\varepsilon_1$ is the random error of the first observation where its expected value is $0$. The residual is the actual value calculated. 

(b) Compute $\sum e_i^2$ and MSE. What is estimated by MSE?

Answer: $\sum e_i^2$ is calculated to be
```{r}
sum(resid21^2)
```

while the MSE is
```{r}
sum(resid21^2)/(nrow(airfreight)-2)
```

The MSE estimates the mean of the residuals squared.

### Problem 26: 
Refer to *Plastic hardness* Problem 1.22.

(a) Obtain the residuals $e_i$. Do they sum to zero in accord with (1.17)?

Answer:
```{r}
resid22 = plastic$y - (ls_est22[1] + ls_est22[2]*plastic$x)
sum(resid22)
```

Due to rounding, they do not sum to zero. Howevery by using `R`'s `lm` function, the residuals do sum to nearly zero.
```{r}
sum(lm(data = plastic, y~x)$residuals)
```

(b) Estimate $\sigma^2$ and $\sigma$. In what units is $\sigma$ expressed?

Answer: $\sigma^2$ and $\sigma$ are, respectively,
```{r}
sd(resid22)^2
sd(resid22)
```

The units of $\sigma$ is Brisnell units.


### Problem 27: 
*Muscle mass.* A person's muscle mass is expected to decrease with age. To explore this relationship in women, a nutritionist randomly selected $15$ women from each $lO$-year age group, beginning with age $40$ and ending with age $79$. The results follow: $X$ is age, and $Y$ is a measure of muscle mass. Assume that first-order regression model (1.1) is appropriate.

(a) Obtain the estimated regression function. Plot the estimated regression function and the data. Does a linear regression function appear to give a good fit here? Does your plot support the anticipation that muscle mass decreases with age?

Answer:
```{r}
muscle = read.csv('CH01PR27.txt', sep = '', header = FALSE, 
                  col.names = c('y', 'x'), 
                  colClasses = c('numeric', 'numeric'))
ls_est27 = lm(data = muscle, y~x)$coef
ggplot(muscle, aes(x,y)) + geom_point(size = 0.8) + 
  geom_abline(intercept = ls_est27[1], slope = ls_est27[2], color = "cadetblue") + 
  labs(title = "Women's Muscle Mass", 
       subtitle = "in comparison to Age", 
       x = "age", y = "muscle mass") + 
  theme_classic()
```

The linear regression function appears to give a good fit to the data here. The plot does support the anticipation that muscle mass decreases with age.

(b) Obtain the following: (1) a point estimate of the difference in the mean muscle mass for women differing in age by one year, (2) a point estimate of the mean muscle mass for women aged $X = 60$ years, (3) the value of the residual for the eighth case, (4) a point estimate of $\sigma^2$.

Answer: (1) The point estimate of the difference in the mean muscle mass for women differing in age by one year is 
```{r}
as.numeric(ls_est27[2])
```

(2) The point estimate of the mean muscle mass for women aged $60$ years is
```{r}
as.numeric(ls_est27[1] + ls_est27[2]*60)
```

(3) The value of the residual for the eighth case is 
```{r}
(muscle$y - (ls_est27[1] + ls_est27*muscle$x))[8]
```

(4) The point estimate of $\sigma^2$ is 
```{r}
sum((muscle$y - (ls_est27[1] + ls_est27*muscle$x))^2) / (nrow(muscle)-2)
```

### Problem 28: 
*Crime rate.* A criminologist studying the relationship between level of education and crime rate in medium-sized U.S. counties collected data for a random sample of $84$ counties; $X$ is the percentage of individuals in the county having at least a high-school diploma, and $Y$ is the crime rate (crimes reported per $100,000$ residents) last year. Assume that first-order regression model (1.1) is appropriate.

(a) Obtain the estimated regression function. Plot the estimated regression function and the data. Does the linear regression function appear to give a good fit here? Discuss.

Answer:
```{r}
crime = read.csv('CH01PR28.txt', sep = '', header = FALSE, 
                  col.names = c('y', 'x'), 
                  colClasses = c('numeric', 'numeric'))
ls_est28 = lm(data = crime, y~x)$coef
ggplot(crime, aes(x,y)) + geom_point(size = 0.8) + 
  geom_abline(intercept = ls_est28[1], slope = ls_est28[2], color = "cadetblue") + 
  labs(title = "Crime Rate", 
       subtitle = "in medium-sized US counties", 
       x = "% of individuals having at least a HS diploma in a county", 
       y = "crime rate, per 100,000 residents") + 
  theme_classic()
```

The linear regression function appears to do an ok job at estimating the crime rate. It could improve by implementing a polynomial fit. 

(b) Obtain point estimates of the following: (1) the difference in the mean crime rate for two counties whose high-school graduation rates differ by one percentage point, (2) the mean crime rate last year in counties with high school graduation percentage $X = 80$, (3) $\varepsilon_{10}$, (4) $\sigma^2$.

Answer: (1) The point estimate of the difference in the mean crime rate for two counties whose high-school graduation rates differ by one point is
```{r}
as.numeric(ls_est28[2])
```

(2) The point estimate of the mean crime rate last year in counties with high school graduation percentage $X=80$ is
```{r}
as.numeric(ls_est28[1] + ls_est28[2]*80)
```

(3) The point estimate of $\varepsilon_{10}$ is
```{r}
(crime$y - (ls_est28[1] + ls_est28*crime$x))[10]
```

(d) The point estimate of $\sigma^2$ is
```{r}
sum((crime$y - (ls_est28[1] + ls_est28*crime$x))^2) / (nrow(crime) - 2)
```

### Problem 29: 
Refer to regression model (1.1). Assume that $X=0$ is within the scope of the model. What is the implication for the regression function if $\beta_0 = 0$ so that the model is $Y_i = \beta_1X_i + \varepsilon_i$? How would the regression function plot on a graph?


### Problem 30: 
Refer to regression model (1.1). What is the implication for the regression function if $\beta_1 = 0$ so that the model is $Y_i = \beta_0 + \varepsilon_i$? How would the regression function plot on a graph?


### Problem 31:
Refer to *Plastic hardness* Problem 1.22. Suppose one test item was molded from a single batch of plastic and the harness of this one item was measured at $16$ different points in time. Would the error term in the regression model for this case still reflect the same effects as for the experiment initually described? Would you expect the error terms for the different points in time to be uncorrelated? Discuss.


### Problem 32: 
Derive the expression for $b_1$ in (1.10a) from the normal equation in (1.9). 


### Problem 33: 
(Calculus needed.) Refer to the regression model $Y_i = \beta_0 + \varepsilon_i$ in Exercise 1.30. Derive the least squares estimator of $\beta_0$ for this model.


### Problem 34: 
Prove that the least squares estimator of $\beta_0$ obtained in Exercise 1.33 is unbiased.


### Problem 35: 
Prove the result in (1.18) - that the sum of the $Y$ observations is the same as the sum of the fitted values.


### Problem 36:
Prove the result in (1.20) - that the sum of the residuals weighted by the fitted values is zero.


### Problem 37: 
Refer to Table l.l for the Toluca Company example. When asked to present a point estimate of the expected work hours for lot sizes of $30$ pieces, a person gave the estimate $202$ because this is the mean number of work hours in the three-runs of size $30$ in the study. A critic states that this person's approach "throws away" most of the data in the study because cases with lot sizes other than $30$ are ignored. Comment.


### Problem 38: 
In *Airfreight breakage* Problem 1.21, the least squares estimates are $b_0 = 10.20$ and $b_1 = 4.00$, and $\sum e_i^2 = 17.60$. Evaluate the least squares criterion $Q$ in (1.8) for the estimates (1) $b_0 = 9$, $b_1 = 3$; (2) $b_0 = 11$, $b_1 = 5$. Is the criterion $Q$ larger for these estimates than for the least squares estimates?


### Problem 39: 
Two observations on $Y$ were obtained at each of three $X$ levels, namely, at $X=5$, $X=10$ and $X=15$.

(a) Show that the least squares regression line fitted to the three points ($5, \overline{Y}_1$), ($10, \overline{Y}_2$) and ($15, \overline{Y}_3$), where $\overline{Y}_1$, $\overline{Y}_2$ and $\overline{Y}_3$ denote the means of the $Y$ observations at the three $X$ levels, is identical to the least squares regression line fitted to the original six cases.

(b) In this study, could the error term variance $\sigma^2$ be estimated without fitting a regression line? Explain.


### Problem 40: 
In fitting regression model (1.1), it was found that observation $Y_i$ fell directly on the fitted regression line (i.e, $Y_i = \hat{Y}_i$). If this case were deleted, would the least squares regression line fitted to the remaining $n-1$ cases be changed? [Hint: What is the contribution of case $i$ to the least squares criterion $Q$?]


### Problem 41: 
(Calculus needed.) Refer to the regression model $Y_i = \beta_1X_i + \varepsilon_i$, $i=1,\dots, n$, in Exercise 1.29. 

(a) Find the least squares estimator of $\beta_1$.

(b) Assume that the error terms $\varepsilon_i$ are independent $N(0, \sigma^2)$ and that $\sigma^2$ is known. State the likelihood function for the $n$ sample observations on $Y$ and obtain the maximum likelihood estimator of $\beta_1$. Is it the same as the least squares estimator?

(c) Show that the maximum likelihood estimator of $\beta_1$ is unbiased.


### Problem 42:
*Typographical errors.* The number of galleys for a manuscript $X$ and the dollar cost of correcting typographical errors $Y$ in a random sample of recent orders are handled by a firm specializing in technical manuscripts. Assume that the regression model $Y_i = \beta_1X_i + \varepsilon_i$ is appropriate, with normally distributed indepent error terms whose variance is $\sigma^2 = 16$. 

(a) State the likelihood function for the six $Y$ observations, for $\sigma^2 = 16$.

(b) Evaluate the likelihood function for $\beta_1 = 17$, $18$ and $19$. For which of these $\beta_1$ values is the likelihood function largest?

(c) The maximum likelihood estimator is $b_1 = \sum X_iY_i / \sum X_i^2$. Find the maximum likelihood estimate. Are your results in part (b) consistent with this estimate? 

(d) Evaluate the likelihood function for values of $\beta_1$ between $\beta_1 = 17$ and $\beta_1 = 19$ and plot the function. Does the point at which the likelihood function is maximized correspond to the maximum likelihood estimate found in part (c)?



### Problem 43: 
Refer to the *CDI* data set in Appendix C.2. The number of active physicians in a CDI ($Y$) is expected to be related to total population, number of hospital beds and total personal income. Assume that first-order regression model (1.1) is appropriate for each of the three predictor variables.

(a) Regress the number og active physicians in turn on each of the three predictor variables. State the estimated regression functions.

(b) Plot the three estimated functions and data on separate graphs. Does a linear regression relation appear to provide a good fit for each of the three predictor variables?

(c) Calculate MSE for each of the three predictor variables. Which predictor variable leads to the smallest variability around the fitted regression line? 


### Problem 44: 
Refer to the *CDI* data set in Appendix C.2

(a) For each geographic region, regress per capita income in a CDI ($Y$) against the percentage of individuals in a county having at least a bachelor's degree ($X$). Assume that first-order regression model (1.1) is appropriate for each region. State the estimated regression functions.

(b) Are the estimated regression functions similar for the four regions? Discuss.

(c) Calcuate MSE for each region. Is the variability around the fitted regression line approximately the same for the four regions? Discuss.


### Problem 45: 
Refer to the *SENIC* data set in Appendix C.1. The average length of stay in a hospital ($Y$) is anticipated to be related to infection risk, available facilities and services, and routine chest X-ray ratio. Assume that first-order regression model (1.1) is appropriate for each of the three predictor variables.

(a) Regress average length of stay on each of the three predictor variables. State the estimated regression functions.

(b) Plot the three estimated regression functions and data on separate graphs. Does a linear relation appear to provide a good fit for each of the three predictor variables?

(c) Calculate MSE for each of the three predictor variables. Which predictor variable leads to the smallest variability around the fitted regression line?


### Problem 46:
Refer to the *SENIC* data set in Appendix C.1.

(a) For each geographic region, regress average length of stay in hospital ($Y$) against infection risk ($X$). Assume that first-order regression model (1.1) is appropriate for each region. State the estimated regression functions.

(b) Are the estimated regression funtions similar for the four regions? Discuss.

(c) Calculate MSE for each region. Is the variability around the fitted regression line approximately the same for the four regions? Discuss.


### Problem 47:
Refer to *Typographical errors* Problem 1.42. Assume that first-order regression model (1.1) is appropriate, with normally distributed independent error terms whose variance is $\sigma^2 = 16$. 

(a) State the likelihood function for the six observations, for $\sigma^2 = 16$.

(b) Obtain the maximum likelihood estimates of $\beta_0$ and $\beta_1$, using (1.27). 
(c) Obtain a three-dimensional plot of the likelihood function for values of $\beta_0$ between $\beta_0 = -10$ and $\beta_0 = 10$ and for values of $\beta_1$ between $\beta_1 = 17$ and $\beta_1 = 19$. Does the likelihood appear to be maximized by the maximum likelihood estimates found in part (b)? 





